#!/usr/bin/env python3
"""
æµ‹è¯• Hugging Face æ¨¡å‹éƒ¨ç½²çŠ¶æ€

ä½¿ç”¨æ–¹æ³•:
python test_model_deployment.py
"""

import os
import sys
from huggingface_hub import InferenceClient, HfApi

def test_model_deployment():
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦æˆåŠŸéƒ¨ç½²"""
    
    # é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œä¸è¦ç¡¬ç¼–ç  tokenï¼‰
    HF_TOKEN = os.getenv("HF_TOKEN", "")
    HF_MODEL = os.getenv("HF_MODEL", "zylandy/mae-intent-classifier")
    
    if not HF_TOKEN:
        print("âŒ è¯·è®¾ç½® HF_TOKEN ç¯å¢ƒå˜é‡")
        print("   ä¾‹å¦‚: export HF_TOKEN='your-token'")
        return False
    
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹éƒ¨ç½²çŠ¶æ€...")
    print("=" * 60)
    print(f"æ¨¡å‹: {HF_MODEL}")
    print(f"Token: {HF_TOKEN[:20]}...")
    
    # æ–¹æ³• 1: æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    print(f"\nğŸ“‹ æ–¹æ³• 1: æ£€æŸ¥æ¨¡å‹ä»“åº“...")
    try:
        api = HfApi(token=HF_TOKEN)
        model_info = api.model_info(HF_MODEL, token=HF_TOKEN)
        print(f"âœ… æ¨¡å‹ä»“åº“å­˜åœ¨")
        print(f"   æ¨¡å‹ ID: {model_info.id}")
        print(f"   æœ€åæ›´æ–°: {model_info.last_modified}")
        
        # åˆ—å‡ºæ–‡ä»¶
        files = [f.rfilename for f in model_info.siblings]
        print(f"\nğŸ“ æ¨¡å‹æ–‡ä»¶ ({len(files)} ä¸ª):")
        for file in sorted(files)[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   - {file}")
        if len(files) > 10:
            print(f"   ... è¿˜æœ‰ {len(files) - 10} ä¸ªæ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ æ— æ³•è®¿é—®æ¨¡å‹ä»“åº“: {e}")
        return False
    
    # æ–¹æ³• 2: ä½¿ç”¨ InferenceClient æµ‹è¯•
    print(f"\nğŸ“¤ æ–¹æ³• 2: ä½¿ç”¨ InferenceClient æµ‹è¯•...")
    try:
        client = InferenceClient(model=HF_MODEL, token=HF_TOKEN)
        
        test_text = "I want to learn about research opportunities"
        print(f"   æµ‹è¯•æ–‡æœ¬: {test_text}")
        
        # å°è¯•æ–‡æœ¬åˆ†ç±»
        try:
            result = client.text_classification(test_text)
            print(f"   âœ… æ–‡æœ¬åˆ†ç±»æˆåŠŸï¼")
            
            # å¤„ç†ç»“æœ
            if isinstance(result, list):
                if result:
                    top = result[0] if isinstance(result[0], dict) else max(result, key=lambda x: x.get("score", 0.0))
                    if isinstance(top, dict):
                        label = top.get("label", "Unknown")
                        score = top.get("score", 0.0)
                        print(f"   ğŸ“Š åˆ†ç±»ç»“æœ:")
                        print(f"      æ„å›¾: {label}")
                        print(f"      ç½®ä¿¡åº¦: {score:.3f}")
                    else:
                        print(f"   ğŸ“Š ç»“æœ: {top}")
            else:
                print(f"   ğŸ“Š ç»“æœ: {result}")
                
            print(f"\nâœ… æ¨¡å‹éƒ¨ç½²æˆåŠŸå¹¶å¯ä»¥ä½¿ç”¨ï¼")
            return True
            
        except Exception as e:
            print(f"   âš ï¸  æ–‡æœ¬åˆ†ç±»å¤±è´¥: {e}")
            print(f"   ğŸ’¡ æç¤º: æ¨¡å‹å¯èƒ½æ­£åœ¨åŠ è½½ï¼Œæˆ–éœ€è¦ä½¿ç”¨ä¸åŒçš„ API æ–¹æ³•")
            
            # å°è¯•å…¶ä»–æ–¹æ³•
            try:
                print(f"\n   å°è¯•ä½¿ç”¨ post æ–¹æ³•...")
                result = client.post(json={"inputs": test_text})
                print(f"   âœ… Post æ–¹æ³•æˆåŠŸï¼")
                print(f"   ç»“æœ: {result}")
                return True
            except Exception as e2:
                print(f"   âŒ Post æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                return False
                
    except Exception as e:
        print(f"âŒ InferenceClient åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_model_deployment()
    sys.exit(0 if success else 1)
