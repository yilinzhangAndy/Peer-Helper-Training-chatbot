#!/usr/bin/env python3
"""
Setup Llama 3.1 8B Instruct for MAE Chatbot
è‡ªåŠ¨å®‰è£…å’Œé…ç½® Llama 3.1 æ¨¡å‹
"""

import subprocess
import sys
import os
import time

def check_ollama():
    """æ£€æŸ¥ Ollama æ˜¯å¦å·²å®‰è£…"""
    try:
        result = subprocess.run(["ollama", "--version"], 
                              capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False

def install_ollama():
    """å®‰è£… Ollama"""
    print("ğŸ“¦ Installing Ollama...")
    try:
        # ä¸‹è½½å¹¶å®‰è£… Ollama
        subprocess.run(["curl", "-fsSL", "https://ollama.ai/install.sh"], 
                      check=True)
        subprocess.run(["sh", "-"], input="curl -fsSL https://ollama.ai/install.sh | sh", 
                      text=True, check=True)
        print("âœ… Ollama installed successfully!")
        return True
    except Exception as e:
        print(f"âŒ Failed to install Ollama: {e}")
        return False

def download_llama3():
    """ä¸‹è½½ Llama 3.1 8B Instruct æ¨¡å‹"""
    print("ğŸ¦™ Downloading Llama 3.1 8B Instruct model...")
    print("â³ This may take 10-20 minutes depending on your internet speed...")
    
    try:
        # ä¸‹è½½æ¨¡å‹
        result = subprocess.run(["ollama", "pull", "llama3.1:8b-instruct"], 
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… Llama 3.1 8B Instruct model downloaded successfully!")
            return True
        else:
            print(f"âŒ Failed to download model: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ Error downloading model: {e}")
        return False

def test_model():
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("ğŸ§ª Testing Llama 3.1 model...")
    
    test_prompt = "Hello, I'm a student. Can you help me with my studies?"
    
    try:
        result = subprocess.run([
            "ollama", "run", "llama3.1:8b-instruct", 
            f"Respond as a helpful peer advisor: {test_prompt}"
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0 and result.stdout.strip():
            print("âœ… Model test successful!")
            print(f"Sample response: {result.stdout.strip()[:100]}...")
            return True
        else:
            print("âŒ Model test failed")
            return False
    except Exception as e:
        print(f"âŒ Error testing model: {e}")
        return False

def main():
    print("ğŸš€ Setting up Llama 3.1 8B Instruct for MAE Chatbot")
    print("=" * 60)
    
    # Step 1: Check/Install Ollama
    if not check_ollama():
        print("Ollama not found. Installing...")
        if not install_ollama():
            print("âŒ Failed to install Ollama. Please install manually:")
            print("   Visit: https://ollama.ai/download")
            return False
    else:
        print("âœ… Ollama already installed")
    
    # Step 2: Download Llama 3.1 model
    if not download_llama3():
        print("âŒ Failed to download model")
        return False
    
    # Step 3: Test model
    if not test_model():
        print("âŒ Model test failed")
        return False
    
    print("\nğŸ‰ Setup complete!")
    print("You can now use Llama 3.1 8B Instruct in your chatbot")
    print("\nNext steps:")
    print("1. Run: streamlit run web_app_llama.py")
    print("2. Enjoy free, high-quality AI responses!")
    
    return True

if __name__ == "__main__":
    main()
