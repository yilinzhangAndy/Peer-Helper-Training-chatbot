# âœ… æ¨¡å‹æ›´æ–°æ€»ç»“

## ğŸ“‹ å½“å‰çŠ¶æ€

- **æ¨¡å‹ä»“åº“**: `zylandy/mae-intent-classifier` âœ…
- **Token**: æœ‰æ•ˆï¼Œæ— éœ€æ›´æ”¹ âœ…
- **é…ç½®**: æ— éœ€æ›´æ”¹ âœ…

## ğŸ” å‘ç°çš„é—®é¢˜

æ¨¡å‹æ–‡ä»¶ä¸Šä¼ åˆ°äº† `checkpoint-3146/` å­ç›®å½•ï¼Œä½† Hugging Face Inference API éœ€è¦æ–‡ä»¶åœ¨**ä»“åº“æ ¹ç›®å½•**ã€‚

### å½“å‰æ–‡ä»¶ç»“æ„ï¼š
```
zylandy/mae-intent-classifier/
  â””â”€â”€ checkpoint-3146/
      â”œâ”€â”€ config.json
      â”œâ”€â”€ model.safetensors
      â”œâ”€â”€ tokenizer_config.json
      â””â”€â”€ ...
```

### éœ€è¦çš„æ–‡ä»¶ç»“æ„ï¼š
```
zylandy/mae-intent-classifier/
  â”œâ”€â”€ config.json          â† å¿…éœ€ï¼šæ¨¡å‹é…ç½®
  â”œâ”€â”€ model.safetensors    â† å¿…éœ€ï¼šæ¨¡å‹æƒé‡
  â”œâ”€â”€ tokenizer_config.json â† å¿…éœ€ï¼šTokenizer é…ç½®
  â”œâ”€â”€ vocab.json           â† å¿…éœ€ï¼šRoBERTa è¯æ±‡è¡¨
  â”œâ”€â”€ merges.txt           â† å¿…éœ€ï¼šRoBERTa BPE åˆå¹¶è§„åˆ™
  â””â”€â”€ special_tokens_map.json â† å¿…éœ€ï¼šç‰¹æ®Š token æ˜ å°„
```

**ä¸ºä»€ä¹ˆéœ€è¦ 6 ä¸ªæ–‡ä»¶ï¼Ÿ**

ä½ çš„æ¨¡å‹æ˜¯ **RoBERTa** ç±»å‹ï¼Œéœ€è¦ï¼š
- **å‰ 3 ä¸ªæ–‡ä»¶**ï¼šæ¨¡å‹æœ¬èº«ï¼ˆconfig + weights + tokenizer configï¼‰
- **å 3 ä¸ªæ–‡ä»¶**ï¼šRoBERTa Tokenizer çš„æ•°æ®æ–‡ä»¶
  - `vocab.json`ï¼šè¯æ±‡è¡¨ï¼ˆå°†è¯è½¬æ¢ä¸º IDï¼‰
  - `merges.txt`ï¼šBPEï¼ˆByte Pair Encodingï¼‰åˆå¹¶è§„åˆ™
  - `special_tokens_map.json`ï¼šç‰¹æ®Š tokenï¼ˆå¦‚ [CLS], [SEP] ç­‰ï¼‰

**å¦‚æœç¼ºå°‘å 3 ä¸ªæ–‡ä»¶**ï¼ŒInference API æ— æ³•æ­£ç¡® tokenize è¾“å…¥æ–‡æœ¬ï¼Œä¼šè¿”å›é”™è¯¯ã€‚

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ³• 1: ç§»åŠ¨æ–‡ä»¶åˆ°æ ¹ç›®å½•ï¼ˆæ¨èï¼‰

1. è®¿é—®æ¨¡å‹é¡µé¢ï¼šhttps://huggingface.co/zylandy/mae-intent-classifier
2. è¿›å…¥ **Files and versions** æ ‡ç­¾
3. å¯¹äºæ¯ä¸ªæ–‡ä»¶ï¼ˆåœ¨ `checkpoint-3146/` ç›®å½•ä¸‹ï¼‰ï¼š
   - ç‚¹å‡»æ–‡ä»¶å³ä¾§çš„ **â‹®** èœå•
   - é€‰æ‹© **Move** æˆ– **Delete and re-upload**
   - å°†æ–‡ä»¶ç§»åŠ¨åˆ°æ ¹ç›®å½•

4. éœ€è¦ç§»åŠ¨çš„æ–‡ä»¶ï¼ˆ**6 ä¸ªæ–‡ä»¶ï¼Œå…¨éƒ¨å¿…éœ€**ï¼‰ï¼š
   - `checkpoint-3146/config.json` â†’ `config.json` âœ… å·²ä¸Šä¼ 
   - `checkpoint-3146/model.safetensors` â†’ `model.safetensors` âœ… å·²ä¸Šä¼ 
   - `checkpoint-3146/tokenizer_config.json` â†’ `tokenizer_config.json` âœ… å·²ä¸Šä¼ 
   - `checkpoint-3146/vocab.json` â†’ `vocab.json` âš ï¸ **è¿˜éœ€è¦ä¸Šä¼ **
   - `checkpoint-3146/merges.txt` â†’ `merges.txt` âš ï¸ **è¿˜éœ€è¦ä¸Šä¼ **
   - `checkpoint-3146/special_tokens_map.json` â†’ `special_tokens_map.json` âš ï¸ **è¿˜éœ€è¦ä¸Šä¼ **

**å½“å‰çŠ¶æ€**ï¼šå·²ä¸Šä¼  3 ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼Œè¿˜éœ€è¦ä¸Šä¼  3 ä¸ª Tokenizer æ–‡ä»¶ã€‚

### æ–¹æ³• 2: ä½¿ç”¨ Gitï¼ˆå¦‚æœç†Ÿæ‚‰ Gitï¼‰

```bash
# å…‹éš†ä»“åº“
git clone https://huggingface.co/zylandy/mae-intent-classifier
cd mae-intent-classifier

# ç§»åŠ¨æ–‡ä»¶
mv checkpoint-3146/config.json .
mv checkpoint-3146/model.safetensors .
mv checkpoint-3146/tokenizer_config.json .
mv checkpoint-3146/vocab.json .
mv checkpoint-3146/merges.txt .
mv checkpoint-3146/special_tokens_map.json .

# æäº¤
git add .
git commit -m "Move model files to root directory"
git push
```

## âœ… éªŒè¯

ç§»åŠ¨æ–‡ä»¶åï¼ŒéªŒè¯ API æ˜¯å¦æ­£å¸¸å·¥ä½œï¼š

```python
import requests

HF_TOKEN = "your-token"
HF_MODEL = "zylandy/mae-intent-classifier"

headers = {"Authorization": f"Bearer {HF_TOKEN}"}
url = f"https://api-inference.huggingface.co/models/{HF_MODEL}"

resp = requests.post(
    url, 
    headers=headers, 
    json={"inputs": "I want to learn about research opportunities"}, 
    timeout=60
)

print(resp.json())
```

## ğŸ“ é…ç½®ç¡®è®¤

**æ— éœ€æ›´æ”¹é…ç½®ï¼** å½“å‰é…ç½®å·²ç»æ­£ç¡®ï¼š

```toml
# Streamlit Secrets æˆ– .streamlit/secrets.toml
HF_MODEL = "zylandy/mae-intent-classifier"  # âœ… æ­£ç¡®
HF_TOKEN = "your-token"  # âœ… Token ä»ç„¶æœ‰æ•ˆï¼Œæ— éœ€æ›´æ”¹
```

## ğŸ¯ æ€»ç»“

1. âœ… **Token**: æ— éœ€æ›´æ”¹ï¼Œä»ç„¶æœ‰æ•ˆ
2. âœ… **æ¨¡å‹åç§°**: æ— éœ€æ›´æ”¹ï¼ˆè¿˜æ˜¯ `zylandy/mae-intent-classifier`ï¼‰
3. âš ï¸ **æ–‡ä»¶ä½ç½®**: éœ€è¦å°†æ–‡ä»¶ä» `checkpoint-3146/` ç§»åŠ¨åˆ°æ ¹ç›®å½•
4. âœ… **é…ç½®**: æ— éœ€æ›´æ”¹

ç§»åŠ¨æ–‡ä»¶åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨æ–°æ¨¡å‹ï¼
