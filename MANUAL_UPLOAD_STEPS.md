# ğŸ“¤ æ‰‹åŠ¨ä¸Šä¼ æ¨¡å‹æ­¥éª¤ï¼ˆæœ€ç®€å•çš„æ–¹æ³•ï¼‰

ç”±äº API æƒé™é™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š

## ğŸ¯ æ–¹æ³• 1: ä½¿ç”¨ Hugging Face Web UIï¼ˆæ¨èï¼‰

### æ­¥éª¤ 1: åˆ›å»ºæ–°æ¨¡å‹ä»“åº“

1. è®¿é—® https://huggingface.co/new
2. é€‰æ‹© **Model** ç±»å‹
3. å¡«å†™ä¿¡æ¯ï¼š
   - **Model name**: `mae-intent-classifier-v2`
   - **Visibility**: Publicï¼ˆæˆ– Privateï¼‰
   - **License**: é€‰æ‹©åˆé€‚çš„è®¸å¯è¯
4. ç‚¹å‡» **Create model**

### æ­¥éª¤ 2: ä¸Šä¼ æ–‡ä»¶

1. è¿›å…¥æ¨¡å‹é¡µé¢ï¼šhttps://huggingface.co/zylandy/mae-intent-classifier-v2
2. ç‚¹å‡» **Files and versions** æ ‡ç­¾
3. ç‚¹å‡» **Add file** â†’ **Upload file**
4. ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶ï¼ˆä» `checkpoint-3146/` ç›®å½•ï¼‰ï¼š
   - âœ… `config.json`
   - âœ… `model.safetensors` (475MB)
   - âœ… `tokenizer_config.json`
   - âœ… `vocab.json`
   - âœ… `merges.txt`
   - âœ… `special_tokens_map.json`

**æ³¨æ„**: ä¸éœ€è¦ä¸Šä¼ è¿™äº›æ–‡ä»¶ï¼š
   - âŒ `optimizer.pt`
   - âŒ `rng_state.pth`
   - âŒ `scheduler.pt`
   - âŒ `trainer_state.json`
   - âŒ `training_args.bin`

### æ­¥éª¤ 3: æ›´æ–°é…ç½®

ä¸Šä¼ å®Œæˆåï¼Œæ›´æ–°é…ç½®ï¼š

**Streamlit Cloud Secrets** æˆ– **.streamlit/secrets.toml**:
```toml
HF_MODEL = "zylandy/mae-intent-classifier-v2"
HF_TOKEN = "your-huggingface-token"  # ä» https://huggingface.co/settings/tokens è·å–
```

## ğŸ¯ æ–¹æ³• 2: ä½¿ç”¨ Git LFSï¼ˆé€‚åˆå¤§æ–‡ä»¶ï¼‰

å¦‚æœ Web UI ä¸Šä¼ å¤±è´¥ï¼ˆæ–‡ä»¶å¤ªå¤§ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ Git LFSï¼š

```bash
# 1. å®‰è£… Git LFS
git lfs install

# 2. å…‹éš†ä»“åº“
git clone https://huggingface.co/zylandy/mae-intent-classifier-v2
cd mae-intent-classifier-v2

# 3. å¤åˆ¶æ–‡ä»¶
cp ../chatbot/checkpoint-3146/config.json .
cp ../chatbot/checkpoint-3146/model.safetensors .
cp ../chatbot/checkpoint-3146/tokenizer_config.json .
cp ../chatbot/checkpoint-3146/vocab.json .
cp ../chatbot/checkpoint-3146/merges.txt .
cp ../chatbot/checkpoint-3146/special_tokens_map.json .

# 4. è®¾ç½® Git LFS è·Ÿè¸ªå¤§æ–‡ä»¶
git lfs track "*.safetensors"

# 5. æäº¤å¹¶æ¨é€
git add .
git commit -m "Upload model files"
git push
```

## ğŸ¯ æ–¹æ³• 3: æ›´æ–°ç°æœ‰æ¨¡å‹ï¼ˆå¦‚æœå·²æœ‰ï¼‰

å¦‚æœä½ æƒ³æ›´æ–°ç°æœ‰çš„ `zylandy/mae-intent-classifier` æ¨¡å‹ï¼š

1. è®¿é—® https://huggingface.co/zylandy/mae-intent-classifier
2. ç‚¹å‡» **Files and versions**
3. åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
4. ä¸Šä¼ æ–°æ–‡ä»¶

ç„¶åæ›´æ–°é…ç½®ï¼š
```toml
HF_MODEL = "zylandy/mae-intent-classifier"  # ä½¿ç”¨ç°æœ‰æ¨¡å‹å
```

## âœ… éªŒè¯ä¸Šä¼ 

ä¸Šä¼ å®Œæˆåï¼Œæµ‹è¯•æ¨¡å‹ï¼š

```python
from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model="zylandy/mae-intent-classifier-v2",
    tokenizer="zylandy/mae-intent-classifier-v2"
)

result = classifier("I want to learn about research opportunities")
print(result)
```

## ğŸ“ éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶æ¸…å•

ä» `checkpoint-3146/` ç›®å½•ä¸Šä¼ ï¼š

### å¿…éœ€æ–‡ä»¶
- [x] `config.json` (1.1 KB)
- [x] `model.safetensors` (475 MB) âš ï¸ å¤§æ–‡ä»¶ï¼Œéœ€è¦ Git LFS æˆ–è€å¿ƒç­‰å¾…
- [x] `tokenizer_config.json` (1.2 KB)
- [x] `vocab.json` (976 KB)
- [x] `merges.txt` (445 KB)
- [x] `special_tokens_map.json` (958 bytes)

### å¯é€‰æ–‡ä»¶
- [ ] `label_mapping.json` (å¦‚æœæœ‰çš„è¯)

### ä¸éœ€è¦ä¸Šä¼ 
- [ ] `optimizer.pt` (è®­ç»ƒç›¸å…³)
- [ ] `rng_state.pth` (è®­ç»ƒç›¸å…³)
- [ ] `scheduler.pt` (è®­ç»ƒç›¸å…³)
- [ ] `trainer_state.json` (è®­ç»ƒç›¸å…³)
- [ ] `training_args.bin` (è®­ç»ƒç›¸å…³)
